{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import numpy.typing as npt \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_IDS = range(0, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(domain: str):\n",
    "\tdir_path = f\"datasets/{domain}\"\n",
    "\n",
    "\tX = []\n",
    "\tY = []\n",
    "\n",
    "\t# matrix (number_drawn, user_id)\n",
    "\t# at each cell we have a list of multiple try of a specific number drawing (number_drawn)\n",
    "\t# drawn by a specific user (user_id), each try contains a list of data points (x, y, z)\n",
    "\thand_gesture_data_matrix = np.zeros((10, 10), dtype=object)\n",
    "\tfor i in range(0, 10):\n",
    "\t\tfor j in range(0, 10):\n",
    "\t\t\thand_gesture_data_matrix[i, j] = []\n",
    "\n",
    "\tfor filename in tqdm(range(1, 1001)):\n",
    "\t\tfile_path = f\"{dir_path}/{filename}.txt\"\n",
    "\t\twith open(file=file_path, mode=\"r\") as f:\n",
    "\t\t\t# get the target, user_id \n",
    "\t\t\t# and a list of positions vectors \\in \\R^3: <x, y, z>\n",
    "\t\t\t# that represents the drawing\n",
    "\t\t\tnumber_drawn, user_id, gesture_datas = load_gesture_data(file=f)\n",
    "\n",
    "\t\t\tX.append(gesture_datas)\n",
    "\t\t\tY.append(number_drawn)\n",
    "\n",
    "\t\t\thand_gesture_data_matrix[number_drawn - 1, user_id - 1].append(gesture_datas)\n",
    "\n",
    "\treturn np.array(X), np.array(Y), hand_gesture_data_matrix\n",
    "\n",
    "def load_gesture_data(file):\n",
    "\t\"\"\" \n",
    "\tStructure of hand gesture dataset:\n",
    "\t-----\n",
    "\tDomain id = <domain-id>\n",
    "\tClass id = <class-id>\n",
    "\tUser id = <user-id>\n",
    "\n",
    "\t<x>,<y>,<z>,<t>\n",
    "\t...\n",
    "\t-----\n",
    "\t\"\"\"\n",
    "\tlines = file.readlines()\n",
    "\t\n",
    "\tnumber_drawn = lines[1].strip()\n",
    "\tmatch_number = re.search(\"=\", number_drawn)\n",
    "\tnumber_drawn = int(match_number.string[match_number.end():].strip())\n",
    "\n",
    "\tuser_id = lines[2].strip()\n",
    "\tmatch_user = re.search(\"=\", user_id)\n",
    "\tuser_id = int(match_user.string[match_user.end():].strip())\n",
    "\n",
    "\tgesture_datas = []\n",
    "\n",
    "\tfor row in range(5, len(lines)):\n",
    "\t\tgesture_data = lines[row].split(\",\")\n",
    "\t\t# we only keep <x, y, z> coordinates\n",
    "\t\tgesture_data = np.array([float(data.strip()) for data in gesture_data[0:-1]])\n",
    "\t\tgesture_datas.append(gesture_data)\n",
    "\t\n",
    "\treturn number_drawn, user_id, gesture_datas\n",
    "\n",
    "X, y, hand_gesture_data_matrix = load_datasets(domain=\"Domain01\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/dynamic-time-warping-3933f25fcdd\n",
    "def DTW_distance(s: npt.NDArray, t: npt.NDArray, window: int = 3) -> float:\n",
    "\tn = len(s)\n",
    "\tm = len(t)\n",
    "\n",
    "\tDTW_matrix = np.full((n+1, m+1), fill_value=np.inf)\n",
    "\tDTW_matrix[0, 0] = 0.0\n",
    "\n",
    "\twindow = max(window, abs(n - m))\n",
    "\n",
    "\tfor i in range(0, n+1):\n",
    "\t\tfor j in range(max(0, i - window), min(m, i + window) + 1):\n",
    "\t\t\tDTW_matrix[i, j] = 0.0\n",
    "\n",
    "\tfor i in range(1, n+1):\n",
    "\t\tfor j in range(max(1, i - window), min(m, i + window) + 1):\n",
    "\t\t\t# manhattan distance\n",
    "\t\t\tcost = distance.cityblock(s[i-1], t[j-1])\n",
    "\t\t\toptimal_warping_path = min(\n",
    "\t\t\t\tDTW_matrix[i-1, j], # insertion\n",
    "\t\t\t\tDTW_matrix[i, j-1], # deletion\n",
    "\t\t\t\tDTW_matrix[i-1, j-1] # match\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\tDTW_matrix[i, j] = cost + optimal_warping_path\n",
    "\t\n",
    "\treturn DTW_matrix[n, m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nbviewer.org/github/markdregan/K-Nearest-Neighbors-with-Dynamic-Time-Warping/blob/master/K_Nearest_Neighbor_Dynamic_Time_Warping.ipynb\n",
    "\n",
    "# http://alexminnaar.com/2014/04/16/Time-Series-Classification-and-Clustering-with-Python.html\n",
    "\n",
    "class KNN:\n",
    "\tdef __init__(self, n_neighbors = 1, distance_fun = DTW_distance):\n",
    "\t\tself.n_neigbors = n_neighbors\n",
    "\t\tself.distance_fun = distance_fun\n",
    "\n",
    "\t\tself.X = None \n",
    "\t\tself.y = None\n",
    "\t\n",
    "\tdef fit(self, X: npt.NDArray, y: npt.NDArray):\n",
    "\t\tself.X = X\n",
    "\t\tself.y = y\n",
    "\n",
    "\tdef distance_matrix(self, X: npt.NDArray, y: npt.NDArray):\n",
    "\t\tn = len(X)\n",
    "\t\tm = len(y)\n",
    "\t\tdistance_matrix = np.zeros((n, m))\n",
    "\n",
    "\t\tfor i in tqdm(range(0, n)):\n",
    "\t\t\tfor j in range(0, m):\n",
    "\t\t\t\tdistance_matrix[i, j] = self.distance_fun(\n",
    "\t\t\t\t\tX[i],\n",
    "\t\t\t\t\ty[i]\n",
    "\t\t\t\t)\n",
    "\t\t\n",
    "\t\treturn distance_matrix\n",
    "\n",
    "\tdef predict(self, X: npt.NDArray):\n",
    "\t\tdistance_matrix = self.distance_matrix(X, self.X)\n",
    "\n",
    "\t\tknn_idx = distance_matrix.argsort()[:, :self.n_neigbors]\n",
    "\t\tknn_labels = self.y[knn_idx]\n",
    "\n",
    "\t\tprediction = mode(knn_labels, axis=1)[0]\n",
    "\t\tproba = mode(knn_labels, axis=1)[1] / self.n_neigbors\n",
    "\n",
    "\t\treturn prediction.ravel(), proba.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, Y, user_id):\n",
    "\tslices = range(user_id, 100 + (user_id * 100))\n",
    "\t\t\n",
    "\tX_train = np.delete(X, slices)\n",
    "\ty_train = np.delete(Y, slices)\n",
    "\n",
    "\tX_test = X[slices]\n",
    "\ty_test = X[slices]\n",
    "\n",
    "\treturn X_train, X_test, y_train, y_test\n",
    "\n",
    "def user_independent_cross_validation(estimator, X, y):\n",
    "\ty_preds = []\n",
    "\tprobas = []\n",
    "\taccuracies = []\n",
    "\n",
    "\tfor user_id in USER_IDS:\n",
    "\t\tX_train, X_test, y_train, y_test = split_dataset(X, y, user_id=user_id)\n",
    "\n",
    "\t\testimator.fit(X_train, y_train)\n",
    "\t\ty_pred, proba = knn.predict(X_test)\n",
    "\n",
    "\t\taccuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\t\taccuracies.append(accuracy)\n",
    "\n",
    "\t\ty_pred.append(y_pred)\n",
    "\t\tprobas.append(proba)\n",
    "\n",
    "\taccuracy_mean = np.mean(accuracies)\n",
    "\taccuracy_std = np.std(accuracies)\n",
    "\t\n",
    "\treturn accuracy_mean, accuracy_std\n",
    "\n",
    "def user_dependent_cross_validation(knn):\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "\tconf_matrix = np.array(confusion_matrix(y_true=y_true, y_pred=y_pred))\n",
    "\tsns.heatmap(conf_matrix, annot=True)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(n_neighbors=1, distance_fun=DTW_distance)\n",
    "\n",
    "accuracy_mean, accuracy_std = user_independent_cross_validation(estimator=knn, X=X, y=y)\n",
    "\n",
    "print(\"DOMAIN 01 - DYNAMIC TIME WARPING\")\n",
    "\n",
    "print(\"USER INDEPENDENT CROSS VALIDATION\")\n",
    "print(f\"mean accuracy: {np.round(accuracy_mean, 3)}\")\n",
    "print(f\"std accuracy: {np.round(accuracy_std, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
