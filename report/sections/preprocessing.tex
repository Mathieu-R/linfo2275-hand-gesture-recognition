\section{Preprocessing}

We first preprocessed the data. We embedded the datas in a list of $1000$ entries. Each entry consist in a matrix of dimension (\textit{n\_timepoints}, \textit{vec\_dimensions}) where \textit{n\_timepoints} is the length of the time series and \textit{vec\_dimensions} is the dimension of the position vector which is $3$ in our case. Notice that each time series has different length, that's important for what is to follow. 
After that, we resampled each time series into $N = 64$ points for the DTW algorithm and into $N=32$ points for the \$P-Recognizer algorithm by performing interpolation. Indeed, performing vector-quantization using a k-means algorithm gave us poor results so we chose to resample by interpolation as proposed in the following article \cite[text]{}. This article claim to resampling time series into $32$ to $64$ points gives good results. We notice it was also the case for the DTW algorithm and choose to limit ourselve to $32$ points for the \$P-Recognizer algorithm as resampling into more points implies too long computation time.

% After that, we compressed the time series to improve the computation time of the algorithms. To do that, we performed a vector quantization by applying a k-means algorithm where each data points is replaced with its closest centroid where the number of centroids correspond to a fraction of the time series length. We decided to reduce the length by half.